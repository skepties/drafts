https://www.scientificamerican.com/article/how-to-convince-someone-when-facts-fail/

![](https://www.scientificamerican.com/sciam/cache/file/9275A3F2-DE6C-4B3C-8090AD8F66863AF0.jpg?w=590&h=393&D82674CC-E1BD-4248-B1BCA13EDDE914FB)

Have you ever noticed that when you present people with facts that are contrary to their deepest held beliefs they always change their minds? Me neither. In fact, people seem to double down on their beliefs in the teeth of overwhelming evidence against them. The reason is related to the worldview perceived to be under threat by the conflicting data.

깊은 믿음을 가진 사람들에게 그 믿음에 반대되는 사실을 보여줬을 때 그들이 보통 자신의 생각을 바꾸던가요? 제 경우엔 그렇지 않더군요. 오히려 현저한 증거들이 있어도 자신들의 믿음을 고수하곤 합니다. 이런 현상의 원인은 자신의 믿음과 반대되는 데이터에 의해서 위협받는 그들의 세계관과 관련이 있습니다.


Creationists, for example, dispute the evidence for evolution in fossils and DNA because they are concerned about secular forces encroaching on religious faith.

예를 들어, 창조주의자들은 종교적인 믿음을 위협하는 세속적인 세력에 대한 염려때문에 화석과 DNA 같은 진화의 증거들에 대해 논쟁합니다.

Anti-vaxxers distrust big pharma and think that money corrupts medicine, which leads them to believe that vaccines cause autism despite the inconvenient truth that the one and only study claiming such a link was retracted and its lead author accused of fraud.

안티백서(백신반대주의자)들이 백신이 자폐증을 일으킨다고 믿는 배경에는 거대 제약회사에 대한 불신과 돈 때문에 의학계가 부패했다는 생각이 있습니다. 사실 백신이 자폐증을 일으킨다는 믿음의 근거는 이미 철회되고 주저자가 사기로 고발된 단 하나의 연구결과밖에 없다는 것이 불편한 진실입니다.

The 9/11 truthers focus on minutiae like the melting point of steel in the World Trade Center buildings that caused their collapse because they think the government lies and conducts “false flag” operations to create a New World Order.

9/11 음모론자들은 미정부가 거짓말을 하고 있고 9/11이 새로운 세계질서를 만들기 위한 미정부의 기만작전(false flag)이라는 믿음 때문에 세계무역센터 철골의 녹는 점과 같은 세부 사항을 파고듭니다.

Climate deniers study tree rings, ice cores and the ppm of greenhouse gases because they are passionate about freedom, especially that of markets and industries to operate unencumbered by restrictive government regulations.

기후변화 부정론자들이 나무의 나이테나 남극의 아이스 코어, 온실가스의 농도에 대 해서 공부하는 이유는 자유주의, 특히 정부의 규제가 없는 자유시장 경제에 대한 열망때문입니다.


Obama birthers desperately dissected the president's long-form birth certificate in search of fraud because they believe that the nation's first African-American president is a socialist bent on destroying the country.

오바마의 출생지를 의심하는 사람들은 미국의 첫 아프리카계 미국인 대통령이 나라를 망치는 사회주의자라는 믿음 때문에 필사적으로 오바마 대통령의 긴 출생 증명서를 연구하고 부정을 찾으려 합니다.


In these examples, proponents' deepest held worldviews were perceived to be threatened by skeptics, making facts the enemy to be slayed.

이러한 예들 처럼, 그들의 견고한 세계관은 회의주의자들에 의해 위협받는 것으로 해석되고, 적을 제거 하기 위한 사실들을 만들어냅니다.


This power of belief over evidence is the result of two factors: cognitive dissonance and the backfire effect.

이런 증거를 넘어서는 믿음의 힘은 인지부조화와 역화효과라는 두 가지 요인에서 비롯됩니다.

In the classic 1956 book When Prophecy Fails, psychologist Leon Festinger and his co-authors described what happened to a UFO cult when the mother ship failed to arrive at the appointed time.

1956년에 발간된 책 "예언이 틀렸을 때 (When prophecy fails)"에서 심리학자 레온 페스팅거와 공저자들은 외계인 모선이 예언된 시간에 도착하지 않았을 때 그 예언을 믿언 UFO 신봉자 들에게 벌어진 일을 설명했습니다.


Instead of admitting error, “members of the group sought frantically to convince the world of their beliefs,” and they made “a series of desperate attempts to erase their rankling dissonance by making prediction after prediction in the hope that one would come true.”

틀린 것을 인정하는 대신, "그룹의 멤버들은 미친듯이 자신들의 믿음을 세상에 납득시키려고 노력했습니다". 그리고 그들은 "그것들이 실현될지도 모른다는 희망 가운데 다른 예언들을 만들어냄으로써 불편한 부조화를 지우려는 일련의 필사적인 시도들"을 만들어냈습니다.

Festinger called this cognitive dissonance, or the uncomfortable tension that comes from holding two conflicting thoughts simultaneously.

페스팅거는 이것을 인지부조화, 혹은 상반된 생각을 동시에 가짐으로 인해 발생하는 불쾌한 긴장 이라고 불렀습니다.

Two social psychologists, Carol Tavris and Elliot Aronson (a former student of Festinger), in their 2007 book Mistakes Were Made (But Not by Me) document thousands of experiments demonstrating how people spin-doctor facts to fit preconceived beliefs to reduce dissonance.

사회 심리학자 캐롤 태프리스와 (페스팅거의 제자였던) 엘리엇 애런슨은 2007년 그들의 책 "거짓말의 진화 - 자기 정당화의 심리학(Mistakes Were Made (But Not by Me))"에서 사람들이 부조화를 줄이고 선입견에 맞추기 위해 어떻게 사실을 조작하는가를 보여주는 수 천개의 실험을 정리했습니다.


Their metaphor of the “pyramid of choice” places two individuals side by side at the apex of the pyramid and shows how quickly they diverge and end up at the bottom opposite corners of the base as they each stake out a position to defend.

그들의 "선택의 피라미드"라는 비유는 피라미드 꼭지점 양쪽의 두 사람이 얼마나 빨리 양쪽으로 나뉘어져서 피라미드 바닥의 양 끝쪽에서 방어를 위한 진지를 구축하는지를 보여줍니다.


In a series of experiments by Dartmouth College professor Brendan Nyhan and University of Exeter professor Jason Reifler, the researchers identify a related factor they call the backfire effect “in which corrections actually increase misperceptions among the group in question.”

다트머스 대학의 브랜든 니한 교수와 엑서터 대학의 제이슨 리플러 교수의 일련의 실험들에서, 연구자들은 "문제에 대한 정정이 실제로는 사람들의 잘못된 생각을 증가시키는" 역화효과라고 불리는 관련된 요인들을 확인했습니다.

Why? “Because it threatens their worldview or self-concept.”

왤까요? "그것이 그들의 세계관이나 자기 가치관을 위협하기 때문입니다."

For example, subjects were given fake newspaper articles that confirmed widespread misconceptions, such as that there were weapons of mass destruction in Iraq.

예를 들어, 피실험자들에게 이라크에 대량 살상 무기가 있다는 것과 같은 널리 알려진 오해를 확인하는 가짜 신문기사가 주어졌습니다.

When subjects were then given a corrective article that WMD were never found, liberals who opposed the war accepted the new article and rejected the old, whereas conservatives who supported the war did the opposite ... and more: they reported being even more convinced there were WMD after the correction, arguing that this only proved that Saddam Hussein hid or destroyed them.

이제 다시 대량 살상무기가 발견되지 않았다는 정정기사가 피실험자들에게 주어지면, 전쟁에 반대하는 자유주의자(진보주의자)들은 이전의 기사를 버리고 새로운 기사를 받아들이지만 전쟁을 지지하던 보수주의자들은 새로운 기사에 반대하고 오히려 정정기사 이후에 사담 후세인이 대량살상무기를 숨겼거나 파괴했다는 것을 증명하는 것 뿐이라고 주장하며 대량살상무기에 대해서 더 확신하게 되었다고 말합니다.


In fact, Nyhan and Reifler note, among many conservatives “the belief that Iraq possessed WMD immediately before the U.S. invasion persisted long after the Bush administration itself concluded otherwise.”

실제로, 니한과 리플러는 많은 보수주의자사이에서  "미국 침공 직전까지도 이라크가 대량살상무기를 보유했다는 믿음은 부시 행정부가 스스로 그렇지 않다는 결론을 내린 후에도 오랬동안 지속되었다"고 말.

If corrective facts only make matters worse, what can we do to convince people of the error of their beliefs? From my experience, 1. keep emotions out of the exchange, 2. discuss, don't attack (no ad hominem and no ad Hitlerum), 3. listen carefully and try to articulate the other position accurately, 4. show respect, 5. acknowledge that you understand why someone might hold that opinion, and 6. try to show how changing facts does not necessarily mean changing worldviews. These strategies may not always work to change people's minds, but now that the nation has just been put through a political fact-check wringer, they may help reduce unnecessary divisiveness.

만약 사실에 대한 정정이 사태를 악화시킬 뿐이라면, 사람들이 가진 믿음의 오류를 납득시키기 위해서 무엇을 할 수 있을 까요? 제 경험에 따르면 1. 대화에 있어 감정을 유지하고, 2. 토론하되 공격하지 말고 ( 인신공격의 오류와 히틀러로의 환원 오류를 저지르지 않고), 3, 신중하게 듣고, 다른 입장을 정확하고 분명하게 말하고, 4. 상대에 대한 존중을 보이고, 5, 누군가 그런 의견을 가질 수 있음을 이해할 수 있다는 것을 알리고, 6. 다른 사실이 반드시 세계관의 변화를 의미하는 것은 아니라는 것을 보여주려고 노력하십시오. 이런 전략들로 항상 사람들의 마음을 바꿀 수 있는 것은 아니지만, 미국이 정치적 팩트 체크라는 시련에 던져진 지금, 불필요한 분열을 줄이는데 도움이 될 것입니다.
